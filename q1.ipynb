{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {"id": "title"},
      "source": [
        "# Q1 â€” Vision Transformer (ViT) on CIFAR-10 (PyTorch)\n",
        "\n",
        "This notebook implements a compact ViT for CIFAR-10 with: patchify, learnable positional embeddings, CLS token, Transformer encoder blocks (MHSA + MLP with residual + LayerNorm), and classification from the CLS token.\n",
        "\n",
        "Run top-to-bottom on Google Colab with GPU. Feel free to tweak the config cell to optimize accuracy." 
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install"},
      "outputs": [],
      "source": [
        "%pip -q install einops timm --upgrade\n",
        "import sys, torch; print('Torch', torch.__version__ if 'torch' in sys.modules else 'not-imported')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "imports"},
      "outputs": [],
      "source": [
        "import math, time, random, os\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from einops import rearrange\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "torch.manual_seed(1337); np.random.seed(1337); random.seed(1337);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "config"},
      "outputs": [],
      "source": [
        "# Training / Model Config\n",
        "config = {\n",
        "    'epochs': 20,\n",
        "    'batch_size': 128,\n",
        "    'lr': 3e-4,\n",
        "    'weight_decay': 0.05,\n",
        "    'num_workers': 2,\n",
        "    # ViT\n",
        "    'img_size': 32,\n",
        "    'patch_size': 4,         # 4 or 8 work well on 32x32\n",
        "    'in_chans': 3,\n",
        "    'num_classes': 10,\n",
        "    'embed_dim': 256,\n",
        "    'depth': 6,\n",
        "    'num_heads': 8,\n",
        "    'mlp_ratio': 4.0,\n",
        "    'dropout': 0.1,\n",
        "}\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "model"},
      "outputs": [],
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=256):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0, 'img_size must be divisible by patch_size'\n",
        "        self.grid = img_size // patch_size\n",
        "        self.num_patches = self.grid * self.grid\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    def forward(self, x):  # B,C,H,W -> B,N,embed\n",
        "        x = self.proj(x)\n",
        "        x = x.flatten(2).transpose(1,2)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, mlp_ratio=4.0, dropout=0.1):\n",
        "        super().__init__()\n",
        "        hidden = int(dim * mlp_ratio)\n",
        "        self.fc1 = nn.Linear(dim, hidden)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden, dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x); x = self.act(x); x = self.drop(x)\n",
        "        x = self.fc2(x); x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        assert dim % num_heads == 0\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        B,N,C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B,N,3,self.num_heads,self.head_dim).permute(2,0,3,1,4)\n",
        "        q,k,v = qkv[0], qkv[1], qkv[2]  # (B,heads,N,head_dim)\n",
        "        attn = (q @ k.transpose(-2,-1)) / math.sqrt(self.head_dim)\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = attn @ v  # (B,heads,N,head_dim)\n",
        "        out = out.transpose(1,2).reshape(B,N,C)\n",
        "        out = self.proj(out)\n",
        "        out = self.drop(out)\n",
        "        return out\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio, dropout):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = Attention(dim, num_heads=num_heads, dropout=dropout)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = MLP(dim, mlp_ratio=mlp_ratio, dropout=dropout)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self, img_size, patch_size, in_chans, num_classes, embed_dim, depth, num_heads, mlp_ratio, dropout):\n",
        "        super().__init__()\n",
        "        self.patch = PatchEmbed(img_size, patch_size, in_chans, embed_dim)\n",
        "        self.cls = nn.Parameter(torch.zeros(1,1,embed_dim))\n",
        "        self.pos = nn.Parameter(torch.zeros(1, 1 + self.patch.num_patches, embed_dim))\n",
        "        self.blocks = nn.Sequential(*[Block(embed_dim, num_heads, mlp_ratio, dropout) for _ in range(depth)])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "        nn.init.trunc_normal_(self.pos, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls, std=0.02)\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "        x = self.patch(x)  # B,N,C\n",
        "        cls = self.cls.expand(B, -1, -1)\n",
        "        x = torch.cat([cls, x], dim=1)\n",
        "        x = x + self.pos\n",
        "        x = self.blocks(x)\n",
        "        x = self.norm(x)\n",
        "        cls_final = x[:,0]\n",
        "        return self.head(cls_final)\n",
        "\n",
        "def build_model(cfg):\n",
        "    return ViT(\n",
        "        img_size=cfg['img_size'], patch_size=cfg['patch_size'], in_chans=cfg['in_chans'],\n",
        "        num_classes=cfg['num_classes'], embed_dim=cfg['embed_dim'], depth=cfg['depth'],\n",
        "        num_heads=cfg['num_heads'], mlp_ratio=cfg['mlp_ratio'], dropout=cfg['dropout']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "data"},
      "outputs": [],
      "source": [
        "# Data\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2470, 0.2435, 0.2616)\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_tf)\n",
        "test_ds  = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_tf)\n",
        "train_loader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'], pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=config['num_workers'], pin_memory=True)\n",
        "len(train_ds), len(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "train_utils"},
      "outputs": [],
      "source": [
        "def accuracy(logits, y):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    return (preds == y).float().mean().item() * 100.0\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_acc, total = 0.0, 0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        b = x.size(0)\n",
        "        total_acc += accuracy(logits, y) * b\n",
        "        total += b\n",
        "    return total_acc / max(1,total)\n",
        "\n",
        "def train(model, train_loader, test_loader, cfg):\n",
        "    model.to(device)\n",
        "    opt = AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])\n",
        "    sched = CosineAnnealingLR(opt, T_max=cfg['epochs'])\n",
        "    best = 0.0\n",
        "    for epoch in range(1, cfg['epochs']+1):\n",
        "        model.train()\n",
        "        t0 = time.time()\n",
        "        for x,y in train_loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        sched.step()\n",
        "        test_acc = evaluate(model, test_loader)\n",
        "        best = max(best, test_acc)\n",
        "        dt = time.time()-t0\n",
        "        print(f'Epoch {epoch:02d}/{cfg[\'epochs\']}: test_acc={test_acc:.2f}% best={best:.2f}% time={dt:.1f}s')\n",
        "    return best\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "run"},
      "outputs": [],
      "source": [
        "model = build_model(config)\n",
        "best_acc = train(model, train_loader, test_loader, config)\n",
        "print('Best CIFAR-10 Test Accuracy (%):', best_acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {"name": "q1.ipynb"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
